{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x_train = [1,2,3]\n",
    "#y_train = [1,2,3]\n",
    "X = tf.placeholder(tf.float32,shape = [None]) #shape = 아무값 들어올수있다(1x100),...\n",
    "Y = tf.placeholder(tf.float32,shape = [None])\n",
    "w = tf.Variable(tf.random_normal([1]),name = 'weight') #tensorflow가 (자체적으로)이용하는 variable, trainable varaible\n",
    "b = tf.Variable(tf.random_normal([1]),name = 'bias')   #w와 b를 랜덤으로 설정\n",
    "\n",
    "hypothesis = X * w  + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) #reduce_mean 평균내줌 (1/m시그마)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01) #최소화 시킨다 train = optimizer.minimize(cost)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) #variable initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 \tCost: 0.48199 \tweight [ 1.61905491] \tbias: [ 1.55446947]\n",
      "step 20 \tCost: 0.380387 \tweight [ 1.60114694] \tbias: [ 1.44079542]\n",
      "step 40 \tCost: 0.332194 \tweight [ 1.62707448] \tbias: [ 1.34638274]\n",
      "step 60 \tCost: 0.290107 \tweight [ 1.65149689] \tbias: [ 1.25820684]\n",
      "step 80 \tCost: 0.253353 \tweight [ 1.6743207] \tbias: [ 1.17580581]\n",
      "step 100 \tCost: 0.221255 \tweight [ 1.69564962] \tbias: [ 1.09880126]\n",
      "step 120 \tCost: 0.193224 \tweight [ 1.71558177] \tbias: [ 1.02683973]\n",
      "step 140 \tCost: 0.168744 \tweight [ 1.73420858] \tbias: [ 0.95959121]\n",
      "step 160 \tCost: 0.147365 \tweight [ 1.75161552] \tbias: [ 0.8967467]\n",
      "step 180 \tCost: 0.128695 \tweight [ 1.76788247] \tbias: [ 0.83801818]\n",
      "step 200 \tCost: 0.11239 \tweight [ 1.78308403] \tbias: [ 0.78313553]\n",
      "step 220 \tCost: 0.0981513 \tweight [ 1.79728997] \tbias: [ 0.73184741]\n",
      "step 240 \tCost: 0.0857162 \tweight [ 1.81056571] \tbias: [ 0.68391806]\n",
      "step 260 \tCost: 0.0748566 \tweight [ 1.82297194] \tbias: [ 0.63912773]\n",
      "step 280 \tCost: 0.0653728 \tweight [ 1.83456564] \tbias: [ 0.59727061]\n",
      "step 300 \tCost: 0.0570906 \tweight [ 1.84540009] \tbias: [ 0.55815494]\n",
      "step 320 \tCost: 0.0498576 \tweight [ 1.8555249] \tbias: [ 0.52160096]\n",
      "step 340 \tCost: 0.043541 \tweight [ 1.86498666] \tbias: [ 0.48744074]\n",
      "step 360 \tCost: 0.0380247 \tweight [ 1.87382889] \tbias: [ 0.45551786]\n",
      "step 380 \tCost: 0.0332072 \tweight [ 1.88209188] \tbias: [ 0.42568567]\n",
      "step 400 \tCost: 0.0290001 \tweight [ 1.88981378] \tbias: [ 0.39780718]\n",
      "step 420 \tCost: 0.025326 \tweight [ 1.89702988] \tbias: [ 0.37175441]\n",
      "step 440 \tCost: 0.0221174 \tweight [ 1.90377355] \tbias: [ 0.34740788]\n",
      "step 460 \tCost: 0.0193153 \tweight [ 1.91007555] \tbias: [ 0.32465595]\n",
      "step 480 \tCost: 0.0168682 \tweight [ 1.91596472] \tbias: [ 0.30339393]\n",
      "step 500 \tCost: 0.0147311 \tweight [ 1.92146838] \tbias: [ 0.28352448]\n",
      "step 520 \tCost: 0.0128648 \tweight [ 1.92661142] \tbias: [ 0.26495618]\n",
      "step 540 \tCost: 0.0112349 \tweight [ 1.9314177] \tbias: [ 0.24760398]\n",
      "step 560 \tCost: 0.00981155 \tweight [ 1.93590915] \tbias: [ 0.23138818]\n",
      "step 580 \tCost: 0.00856849 \tweight [ 1.94010651] \tbias: [ 0.21623443]\n",
      "step 600 \tCost: 0.00748292 \tweight [ 1.94402909] \tbias: [ 0.20207304]\n",
      "step 620 \tCost: 0.00653488 \tweight [ 1.94769454] \tbias: [ 0.18883906]\n",
      "step 640 \tCost: 0.00570697 \tweight [ 1.95112014] \tbias: [ 0.1764718]\n",
      "step 660 \tCost: 0.00498393 \tweight [ 1.95432138] \tbias: [ 0.16491449]\n",
      "step 680 \tCost: 0.0043525 \tweight [ 1.95731294] \tbias: [ 0.15411404]\n",
      "step 700 \tCost: 0.00380108 \tweight [ 1.96010852] \tbias: [ 0.14402096]\n",
      "step 720 \tCost: 0.00331951 \tweight [ 1.96272099] \tbias: [ 0.1345889]\n",
      "step 740 \tCost: 0.00289894 \tweight [ 1.9651624] \tbias: [ 0.12577455]\n",
      "step 760 \tCost: 0.00253167 \tweight [ 1.96744394] \tbias: [ 0.11753751]\n",
      "step 780 \tCost: 0.00221093 \tweight [ 1.96957624] \tbias: [ 0.10983986]\n",
      "step 800 \tCost: 0.00193081 \tweight [ 1.97156858] \tbias: [ 0.10264632]\n",
      "step 820 \tCost: 0.00168618 \tweight [ 1.97343063] \tbias: [ 0.09592392]\n",
      "step 840 \tCost: 0.00147258 \tweight [ 1.97517073] \tbias: [ 0.08964182]\n",
      "step 860 \tCost: 0.00128601 \tweight [ 1.97679675] \tbias: [ 0.0837711]\n",
      "step 880 \tCost: 0.00112309 \tweight [ 1.97831631] \tbias: [ 0.07828491]\n",
      "step 900 \tCost: 0.000980796 \tweight [ 1.97973645] \tbias: [ 0.07315796]\n",
      "step 920 \tCost: 0.000856528 \tweight [ 1.9810636] \tbias: [ 0.06836671]\n",
      "step 940 \tCost: 0.000748017 \tweight [ 1.98230374] \tbias: [ 0.06388928]\n",
      "step 960 \tCost: 0.000653247 \tweight [ 1.98346269] \tbias: [ 0.0597051]\n",
      "step 980 \tCost: 0.000570487 \tweight [ 1.98454571] \tbias: [ 0.05579497]\n",
      "step 1000 \tCost: 0.000498213 \tweight [ 1.98555779] \tbias: [ 0.05214091]\n",
      "step 1020 \tCost: 0.000435095 \tweight [ 1.9865036] \tbias: [ 0.04872617]\n",
      "step 1040 \tCost: 0.000379968 \tweight [ 1.98738754] \tbias: [ 0.04553505]\n",
      "step 1060 \tCost: 0.000331828 \tweight [ 1.98821354] \tbias: [ 0.04255293]\n",
      "step 1080 \tCost: 0.00028979 \tweight [ 1.98898542] \tbias: [ 0.03976611]\n",
      "step 1100 \tCost: 0.000253077 \tweight [ 1.98970675] \tbias: [ 0.03716188]\n",
      "step 1120 \tCost: 0.000221011 \tweight [ 1.99038088] \tbias: [ 0.03472815]\n",
      "step 1140 \tCost: 0.000193012 \tweight [ 1.9910109] \tbias: [ 0.03245373]\n",
      "step 1160 \tCost: 0.000168558 \tweight [ 1.99159968] \tbias: [ 0.03032824]\n",
      "step 1180 \tCost: 0.000147202 \tweight [ 1.99214971] \tbias: [ 0.02834204]\n",
      "step 1200 \tCost: 0.000128551 \tweight [ 1.99266386] \tbias: [ 0.02648586]\n",
      "step 1220 \tCost: 0.000112267 \tweight [ 1.99314427] \tbias: [ 0.02475129]\n",
      "step 1240 \tCost: 9.80449e-05 \tweight [ 1.99359322] \tbias: [ 0.02313028]\n",
      "step 1260 \tCost: 8.56217e-05 \tweight [ 1.99401283] \tbias: [ 0.02161546]\n",
      "step 1280 \tCost: 7.47722e-05 \tweight [ 1.99440503] \tbias: [ 0.02019979]\n",
      "step 1300 \tCost: 6.52995e-05 \tweight [ 1.99477136] \tbias: [ 0.01887689]\n",
      "step 1320 \tCost: 5.70276e-05 \tweight [ 1.99511385] \tbias: [ 0.01764067]\n",
      "step 1340 \tCost: 4.98017e-05 \tweight [ 1.99543381] \tbias: [ 0.01648533]\n",
      "step 1360 \tCost: 4.3492e-05 \tweight [ 1.99573278] \tbias: [ 0.01540569]\n",
      "step 1380 \tCost: 3.79845e-05 \tweight [ 1.99601233] \tbias: [ 0.01439676]\n",
      "step 1400 \tCost: 3.31721e-05 \tweight [ 1.99627352] \tbias: [ 0.01345392]\n",
      "step 1420 \tCost: 2.8969e-05 \tweight [ 1.99651754] \tbias: [ 0.01257282]\n",
      "step 1440 \tCost: 2.52982e-05 \tweight [ 1.99674559] \tbias: [ 0.01174941]\n",
      "step 1460 \tCost: 2.2093e-05 \tweight [ 1.99695873] \tbias: [ 0.01097997]\n",
      "step 1480 \tCost: 1.92934e-05 \tweight [ 1.99715793] \tbias: [ 0.01026093]\n",
      "step 1500 \tCost: 1.6849e-05 \tweight [ 1.99734402] \tbias: [ 0.00958895]\n",
      "step 1520 \tCost: 1.47156e-05 \tweight [ 1.99751806] \tbias: [ 0.00896094]\n",
      "step 1540 \tCost: 1.28498e-05 \tweight [ 1.99768043] \tbias: [ 0.00837409]\n",
      "step 1560 \tCost: 1.12222e-05 \tweight [ 1.99783242] \tbias: [ 0.00782573]\n",
      "step 1580 \tCost: 9.80016e-06 \tweight [ 1.9979744] \tbias: [ 0.00731325]\n",
      "step 1600 \tCost: 8.55956e-06 \tweight [ 1.99810696] \tbias: [ 0.00683434]\n",
      "step 1620 \tCost: 7.47487e-06 \tweight [ 1.99823105] \tbias: [ 0.00638674]\n",
      "step 1640 \tCost: 6.52796e-06 \tweight [ 1.99834681] \tbias: [ 0.00596846]\n",
      "step 1660 \tCost: 5.70166e-06 \tweight [ 1.99845505] \tbias: [ 0.00557759]\n",
      "step 1680 \tCost: 4.97933e-06 \tweight [ 1.99855614] \tbias: [ 0.00521233]\n",
      "step 1700 \tCost: 4.34846e-06 \tweight [ 1.99865079] \tbias: [ 0.00487104]\n",
      "step 1720 \tCost: 3.79733e-06 \tweight [ 1.99873912] \tbias: [ 0.00455208]\n",
      "step 1740 \tCost: 3.31611e-06 \tweight [ 1.99882174] \tbias: [ 0.00425396]\n",
      "step 1760 \tCost: 2.89587e-06 \tweight [ 1.99889874] \tbias: [ 0.00397545]\n",
      "step 1780 \tCost: 2.5295e-06 \tweight [ 1.99897087] \tbias: [ 0.00371518]\n",
      "step 1800 \tCost: 2.20867e-06 \tweight [ 1.99903822] \tbias: [ 0.00347193]\n",
      "step 1820 \tCost: 1.92914e-06 \tweight [ 1.9991014] \tbias: [ 0.00324457]\n",
      "step 1840 \tCost: 1.68476e-06 \tweight [ 1.99915993] \tbias: [ 0.00303217]\n",
      "step 1860 \tCost: 1.47144e-06 \tweight [ 1.99921501] \tbias: [ 0.00283368]\n",
      "step 1880 \tCost: 1.28505e-06 \tweight [ 1.99926639] \tbias: [ 0.00264816]\n",
      "step 1900 \tCost: 1.12222e-06 \tweight [ 1.99931443] \tbias: [ 0.0024748]\n",
      "step 1920 \tCost: 9.8034e-07 \tweight [ 1.99935937] \tbias: [ 0.00231272]\n",
      "step 1940 \tCost: 8.56067e-07 \tweight [ 1.99940121] \tbias: [ 0.0021613]\n",
      "step 1960 \tCost: 7.47671e-07 \tweight [ 1.99944043] \tbias: [ 0.00201983]\n",
      "step 1980 \tCost: 6.52887e-07 \tweight [ 1.99947715] \tbias: [ 0.00188758]\n",
      "step 2000 \tCost: 5.70188e-07 \tweight [ 1.99951124] \tbias: [ 0.00176401]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val,w_val,b_val,_ = sess.run([cost,w,b,train],feed_dict = {X:[1,2,3,4,5],Y:[2,4,6,8,10]})\n",
    "    if step % 20 == 0:\n",
    "        print(\"step\",step,\"\\tCost:\",cost_val,\"\\tweight\",w_val,\"\\tbias:\",b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.99932098]\n",
      "[ 3.00103092  7.00005293]\n"
     ]
    }
   ],
   "source": [
    "#Testing out model\n",
    "print(sess.run(hypothesis,feed_dict={X:[5]}))\n",
    "print(sess.run(hypothesis,feed_dict={X:[1.5,3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
